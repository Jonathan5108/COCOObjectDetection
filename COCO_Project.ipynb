{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Pid2l1VnpfMa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9de4b95b-74ed-414a-c54a-8a1904639971"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.2.54-py3-none-any.whl (800 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/800.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m378.9/800.1 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m800.1/800.1 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0.0,>=1.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.25.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.1)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.8.0.76)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.4.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.1)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.31.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.11.4)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.3.0+cu121)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.18.0+cu121)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.4)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.0.3)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.1)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.0-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.53.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2024.6.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m35.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, ultralytics-thop, ultralytics\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.82 nvidia-nvtx-cu12-12.1.105 ultralytics-8.2.54 ultralytics-thop-2.0.0\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.10/dist-packages (2.0.8)\n",
            "Requirement already satisfied: matplotlib>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from pycocotools) (3.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pycocotools) (1.25.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools) (4.53.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=2.1.0->pycocotools) (1.16.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.6.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install ultralytics\n",
        "!pip install pycocotools\n",
        "!pip install requests tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import requests\n",
        "from zipfile import ZipFile\n",
        "from tqdm import tqdm\n",
        "\n",
        "urls = {\n",
        "    'train2017': 'http://images.cocodataset.org/zips/train2017.zip',\n",
        "    'val2017': 'http://images.cocodataset.org/zips/val2017.zip',\n",
        "    'annotations': 'http://images.cocodataset.org/annotations/annotations_trainval2017.zip'\n",
        "}\n",
        "os.makedirs('coco_dataset', exist_ok=True)\n",
        "os.chdir('coco_dataset')\n",
        "\n",
        "# Downloads and extracts zip files from the specified url\n",
        "def download_and_extract(url, dest):\n",
        "    # Get request from URL\n",
        "    response = requests.get(url, stream=True)\n",
        "    # Calculates size of the file\n",
        "    total_size = int(response.headers.get('content-length', 0))\n",
        "    block_size = 1024\n",
        "    t = tqdm(total=total_size, unit='iB', unit_scale=True)\n",
        "    # Open and save data to file\n",
        "    with open(dest, 'wb') as file:\n",
        "        for data in response.iter_content(block_size):\n",
        "            t.update(len(data))\n",
        "            file.write(data)\n",
        "    t.close()\n",
        "    # Extract zipfile contents\n",
        "    with ZipFile(dest, 'r') as zip_ref:\n",
        "        zip_ref.extractall()\n",
        "    # Clean up the zipfile after contents extracted\n",
        "    os.remove(dest)\n",
        "\n",
        "# Populates our local Colab Environment with the COCO Dataset's training,\n",
        "# validation, and annotation datasets\n",
        "for name, url in urls.items():\n",
        "    download_and_extract(url, f\"{name}.zip\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S1fQdWLDqMwM",
        "outputId": "2dc8a954-9f49-4d33-d060-391e47105cdc"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 19.3G/19.3G [20:07<00:00, 16.0MiB/s]\n",
            "100%|██████████| 816M/816M [01:26<00:00, 9.42MiB/s]\n",
            "100%|██████████| 253M/253M [00:20<00:00, 12.3MiB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import shutil\n",
        "import random\n",
        "# Load COCO annotations\n",
        "with open('/content/coco_dataset/annotations/instances_train2017.json') as f:\n",
        "    annotations = json.load(f)\n",
        "\n",
        "# Define what objects from COCO we are looking to detect\n",
        "categories_of_interest = ['toothbrush', 'scissors', 'mouse']\n",
        "category_ids = [category['id'] for category in annotations['categories'] if\n",
        "                category['name'] in categories_of_interest]\n",
        "# Create directories for the YOLOv8 images and labels datasets\n",
        "os.makedirs('/content/coco_dataset/yolo_data/images/train', exist_ok=True)\n",
        "os.makedirs('/content/coco_dataset/yolo_data/images/val', exist_ok=True)\n",
        "os.makedirs('/content/coco_dataset/yolo_data/labels/train', exist_ok=True)\n",
        "os.makedirs('/content/coco_dataset/yolo_data/labels/val', exist_ok=True)\n",
        "\n",
        "subset_size = 40000 # Increase depending on how much of COCO dataset we want to train on\n",
        "subset_images = annotations['images'][:subset_size]\n",
        "\n",
        "# Dataset 80/20 split\n",
        "random.shuffle(subset_images)\n",
        "split_index = int(0.8 * len(subset_images))\n",
        "train_images = subset_images[:split_index]\n",
        "val_images = subset_images[split_index:]\n",
        "\n",
        "# Training image annotation conversions\n",
        "for image in tqdm(train_images):\n",
        "    image_id = image['id']\n",
        "    file_name = image['file_name']\n",
        "    height = image['height']\n",
        "    width = image['width']\n",
        "    # Get all relevant annotations in our categories of interest\n",
        "    image_annotations = [ann for ann in annotations['annotations'] if ann['image_id']\n",
        "                         == image_id and ann['category_id'] in category_ids]\n",
        "    if image_annotations:\n",
        "        # Copy image and labels to appropriate corresponding YOLO directory\n",
        "        src_img_path = os.path.join('train2017', file_name)\n",
        "        dest_img_path = os.path.join('/content/coco_dataset/yolo_data/images/train',\n",
        "                                     file_name)\n",
        "        shutil.copyfile(src_img_path, dest_img_path)\n",
        "        label_file_path = os.path.join('/content/coco_dataset/yolo_data/labels/train',\n",
        "                                       file_name.replace('.jpg', '.txt'))\n",
        "        # Create YOLO formatted label file from our COCO annotation information\n",
        "        # (X_Center and Y_Center used instead of X_min and height vars for example)\n",
        "        with open(label_file_path, 'w') as label_file:\n",
        "            for annotation in image_annotations:\n",
        "                bbox = annotation['bbox']\n",
        "                category_id = annotation['category_id']\n",
        "                x_center = (bbox[0] + bbox[2]/2) / width\n",
        "                y_center = (bbox[1] + bbox[3]/2) / height\n",
        "                w = bbox[2] / width\n",
        "                h = bbox[3] / height\n",
        "                label_file.write(f\"{category_ids.index(category_id)} {x_center} \"\n",
        "                                f\"{y_center} {w} {h}\\n\")\n",
        "# Validation image annotation conversions\n",
        "for image in tqdm(val_images):\n",
        "    image_id = image['id']\n",
        "    file_name = image['file_name']\n",
        "    height = image['height']\n",
        "    width = image['width']\n",
        "    # Get all relevant annotations in our categories of interest\n",
        "    image_annotations = [ann for ann in annotations['annotations'] if ann['image_id']\n",
        "                         == image_id and ann['category_id'] in category_ids]\n",
        "    if image_annotations:\n",
        "      # Copy image and labels to appropriate corresponding YOLO directory\n",
        "        src_img_path = os.path.join('train2017', file_name)\n",
        "        dest_img_path = os.path.join('/content/coco_dataset/yolo_data/images/val',\n",
        "                                     file_name)\n",
        "        shutil.copyfile(src_img_path, dest_img_path)\n",
        "        label_file_path = os.path.join('/content/coco_dataset/yolo_data/labels/val',\n",
        "                                       file_name.replace('.jpg', '.txt'))\n",
        "        # Create YOLO formatted label file from our COCO annotation information\n",
        "        # (X_Center and Y_Center used instead of X_min and height vars for example)\n",
        "        with open(label_file_path, 'w') as label_file:\n",
        "            for annotation in image_annotations:\n",
        "                bbox = annotation['bbox']\n",
        "                category_id = annotation['category_id']\n",
        "                x_center = (bbox[0] + bbox[2]/2) / width\n",
        "                y_center = (bbox[1] + bbox[3]/2) / height\n",
        "                w = bbox[2] / width\n",
        "                h = bbox[3] / height\n",
        "                label_file.write(f\"{category_ids.index(category_id)} {x_center} \"\n",
        "                                f\"{y_center} {w} {h}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VdD3t3hNxVF1",
        "outputId": "147dd163-bbe2-43cf-b322-2374046adbc1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 96%|█████████▌| 30769/32000 [1:23:22<03:18,  6.21it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write to the COCO YAML configuration file with 3 classes (for our 3 objects) and the specified paths for our training and validation image datasets"
      ],
      "metadata": {
        "id": "sB5Of77VdtCp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# COCO YAML Configuration File\n",
        "coco_yaml_content = \"\"\"\n",
        "train: ./yolo_data/images/train\n",
        "val: ./yolo_data/images/val\n",
        "\n",
        "nc: 3\n",
        "names: ['mouse', 'scissors', 'toothbrush']\n",
        "\"\"\"\n",
        "\n",
        "with open(\"/content/coco_dataset/coco.yaml\", \"w\") as file:\n",
        "    file.write(coco_yaml_content)"
      ],
      "metadata": {
        "id": "8tVfnGBr0Qhb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Training (Epochs to be determined) Using YOLOv8n model"
      ],
      "metadata": {
        "id": "P_37aBoru3av"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "model = YOLO('yolov8n.pt')\n",
        "\n",
        "# Train model (More epochs can be done at expense of computational power)\n",
        "model.train(data='/content/coco_dataset/coco.yaml',\n",
        "            epochs=150,\n",
        "            imgsz=640,\n",
        "            batch=16,\n",
        "            name='yolov8_coco',\n",
        "            workers=4)\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "_DPDwStjyOOl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create zipped file containing model w/ weights"
      ],
      "metadata": {
        "id": "BLrvBUlajhdP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "from google.colab import files\n",
        "\n",
        "shutil.make_archive('yolov8_coco', 'zip', '/content/runs/train/yolov8_coco')\n",
        "files.download('yolov8_coco.zip')"
      ],
      "metadata": {
        "id": "JVKAJEjkCEIf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# Visualize\n",
        "def plot_boxes(img, boxes, confidences, class_ids):\n",
        "    for box, conf, cls in zip(boxes, confidences, class_ids): # Iterate using zip\n",
        "        x1, y1, x2, y2 = box\n",
        "        label = f'{model.names[int(cls)]} {conf:.2f}'\n",
        "        cv2.rectangle(img, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)\n",
        "        cv2.putText(img, label, (int(x1), int(y1) - 10), cv2.FONT_HERSHEY_SIMPLEX,\n",
        "                    0.5, (0, 255, 0), 2)\n",
        "    return img\n",
        "\n",
        "# Path to the image\n",
        "image_path = '/content/scissorsopen.jpg'\n",
        "image = Image.open(image_path)\n",
        "image = np.array(image)\n",
        "\n",
        "# Resulting bounding boxes predicted by model\n",
        "results = model(image_path)\n",
        "\n",
        "if results[0].boxes.xyxy is not None:\n",
        "    boxes = results[0].boxes.xyxy.cpu().numpy()  #.cpu for CPU usage, remove otherwise\n",
        "    confidences = results[0].boxes.conf.cpu().numpy()\n",
        "    class_ids = results[0].boxes.cls.cpu().numpy()\n",
        "else:\n",
        "    boxes = []\n",
        "    confidences = []\n",
        "    class_ids = []\n",
        "\n",
        "# Plot the image with bounding boxes\n",
        "img_with_boxes = plot_boxes(image.copy(), boxes, confidences, class_ids) # Pass\n",
        "# confidences and class IDs\n",
        "\n",
        "# Display the image\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.imshow(img_with_boxes)\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "JYkRylOmDduO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}